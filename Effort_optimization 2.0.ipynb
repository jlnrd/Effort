{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import pandas as pd\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import optimize\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_samples = 10000\n",
    "threshold = .5 \n",
    "REWARD = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free parameters to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#COST = 0.5\n",
    "#B=6\n",
    "#A=60 \n",
    "#u_skill = .625 #mean of beta\n",
    "#tao_skill = 20 #variance of beta\n",
    "#skill=.4\n",
    "#scale = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prob_reward(e,diff,skill, A, B):\n",
    "    \"\"\"Return the probability of getting the reward\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    e : numeric or array-like\n",
    "        Description of this parameter.\n",
    "    # TODO: list other parameters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ...\n",
    "    \"\"\"\n",
    "    return 1/(1 + A * np.exp(-(e * skill / diff) * B)) \n",
    "\n",
    "def get_effort(cost, diff, skill, A, B,reward=1):\n",
    "    \"\"\"Documentation.\"\"\"\n",
    "    es = np.linspace(0, 1, 100) \n",
    "    utilities = (\n",
    "        reward * prob_reward(e=es, diff=diff, skill=skill, A=A, B=B)\n",
    "        - cost * es\n",
    "    )\n",
    "    return es[np.argmax(utilities)]  #return argmax of utility\n",
    "\n",
    "def your_eff_know_skill(n_samples, cost, diff, skill, A, B,reward=1):  #model for planning. Takes in diff, skill, and cost -returns effort\n",
    "    \"\"\"Documentation.\"\"\"\n",
    "    sampled_effort = np.empty(n_samples)\n",
    "    for i in xrange(n_samples):\n",
    "        d = np.random.choice(diff)\n",
    "        effort=get_effort(cost=cost, diff=d, skill=skill, A=A, B=B, reward=reward)\n",
    "        sampled_effort[i] = effort\n",
    "    \n",
    "    return sampled_effort\n",
    "\n",
    "\n",
    "def create_priors(n_samples, tao_skill, u_skill, cost, A, B, reward=1,threshold=0.5):\n",
    "    \"\"\"Documentation.\"\"\"\n",
    "    # Skill and diff are beta distributions.\n",
    "    skills = np.random.beta(\n",
    "        tao_skill * u_skill, (1 - u_skill) * tao_skill, size=n_samples,\n",
    "    )\n",
    "    diffs = np.random.beta(.5,.5, size=n_samples)\n",
    "\n",
    "    # Create array of effort values, for each value of skill and diff.\n",
    "    # This initializes an empty array and fills in a value with each \n",
    "    # iteration.\n",
    "    # TODO: this seems to be the bottleneck. Is there any way this can\n",
    "    #       be vectorized?\n",
    "    efforts = np.empty_like(skills)\n",
    "    for ii, (this_skill, this_diff) in enumerate(zip(skills, diffs)):\n",
    "        efforts[ii] = get_effort(\n",
    "            cost=cost, skill=this_skill, diff=this_diff, A=A, B=B\n",
    "        )\n",
    "\n",
    "    high_effort = efforts > threshold\n",
    "    success = prob_reward(efforts, diffs, skills, A, B) > np.random.random(n_samples)\n",
    "\n",
    "    return skills, diffs, success, high_effort\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that takes in free parameters and spits out model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_model(cost, A, B, u_skill,tao_skill, skill, scale,n_samples=1000):\n",
    "    REWARD=1\n",
    "    skills, diffs, success, high_effort= create_priors(\n",
    "        n_samples =n_samples, tao_skill=tao_skill, u_skill=u_skill, cost=cost, A=A, B=B\n",
    "    )\n",
    "\n",
    "    effort_high_success = your_eff_know_skill(n_samples, cost, diffs[success & high_effort],skill, A,B) \n",
    "    effort_low_success = your_eff_know_skill(n_samples,  cost, diffs[success & (~high_effort)],skill,A,B) \n",
    "    effort_high_fail = your_eff_know_skill(n_samples,  cost, diffs[(~success) & high_effort],skill,A,B) \n",
    "    effort_low_fail = your_eff_know_skill(n_samples,  cost, diffs[(~success) & (~high_effort)],skill,A,B) \n",
    "    effort_baseline = your_eff_know_skill(n_samples,  cost, np.random.beta(.5, .5, size=n_samples),skill,A,B)\n",
    "\n",
    "    index=['High Effort Success', 'Low Effort Success', 'High Effort Failure', 'Low Effort Failure',\"Baseline\"]\n",
    "    d = {\n",
    "        'Model' : pd.Series(\n",
    "            [ \n",
    "                np.mean(effort_high_success) * scale, \n",
    "                np.mean(effort_low_success) * scale, \n",
    "                np.mean(effort_high_fail) * scale, \n",
    "                np.mean(effort_low_fail) * scale, \n",
    "                np.mean(effort_baseline)*scale\n",
    "            ], index=index),\n",
    "         'Human' : pd.Series(\n",
    "            [107, 57, 30, 35,86], \n",
    "            index=index)}\n",
    "    \n",
    "    df = pd.DataFrame(d)\n",
    "    rmse_val = rmse( df['Model'],df['Human'])\n",
    "    return rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrapped_run_model(x):\n",
    "    return run_model(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 226 ms per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.94004073777716"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([0.5,60,6, .625, 20, .4, 200])\n",
    "%timeit wrapped_run_model(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optminize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_words=dict(cost = 0.5,B=6,A=60 ,u_skill = .625 ,tao_skill = 20, skill=.4, scale =200)\n",
    "rmse_val= run_model(**key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([0.5,60,6, .625, 20, .4, 200])\n",
    "minimum = optimize.fmin(wrapped_run_model, inputs, maxiter =1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.45503125,   61.4582183 ,    6.13676878,    0.63085187,\n",
       "         20.34939935,    0.40989297,  204.30968831])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = 0.5\n",
    "B=6\n",
    "A=60 \n",
    "u_skill = .625 #mean of beta\n",
    "tao_skill = 20 #variance of beta\n",
    "skill=.4\n",
    "scale = 200\n",
    "threshold = .5\n",
    "skills, diffs, success, high_effort=create_priors(1000, tao_skill, u_skill, cost, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "efforthigh_success = your_eff_know_skill(1000,cost, diffs[success & high_effort],skill, A,B) \n",
    "effortlow_success = your_eff_know_skill(1000,cost, diffs[success & (~high_effort)],skill,A,B) \n",
    "efforthigh_fail = your_eff_know_skill(1000,cost, diffs[(~success) & high_effort],skill,A,B) \n",
    "effortlow_fail = your_eff_know_skill(1000,cost, diffs[(~success) & (~high_effort)],skill,A,B) \n",
    "effortbaseline = your_eff_know_skill(1000,cost, np.random.beta(.5, .5, size=100),skill,A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Human</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>High Effort Success</th>\n",
       "      <td>107</td>\n",
       "      <td>94.309091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low Effort Success</th>\n",
       "      <td>57</td>\n",
       "      <td>55.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High Effort Failure</th>\n",
       "      <td>30</td>\n",
       "      <td>29.325253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low Effort Failure</th>\n",
       "      <td>35</td>\n",
       "      <td>6.096970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>85</td>\n",
       "      <td>66.597980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Human      Model\n",
       "High Effort Success    107  94.309091\n",
       "Low Effort Success      57  55.747475\n",
       "High Effort Failure     30  29.325253\n",
       "Low Effort Failure      35   6.096970\n",
       "Baseline                85  66.597980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 200\n",
    "d = {'Model' : pd.Series([np.mean(efforthigh_success)*scale, np.mean(effortlow_success)*scale, np.mean(efforthigh_fail)*scale, np.mean(effortlow_fail)*scale, np.mean(effortbaseline)*scale], index=['High Effort Success', 'Low Effort Success', 'High Effort Failure', 'Low Effort Failure',\"Baseline\"]),\n",
    "     'Human' : pd.Series([107, 57, 30, 35,85], index=['High Effort Success', 'Low Effort Success', 'High Effort Failure', 'Low Effort Failure',\"Baseline\"])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
