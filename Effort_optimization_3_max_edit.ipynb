{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julialeonard/anaconda/lib/python2.7/site-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.0.1 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n",
      "/Users/julialeonard/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:913: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import glob as glob\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import optimize\n",
    "\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_samples = 10000\n",
    "threshold = .5 \n",
    "REWARD = 1\n",
    "\n",
    "_results_index = [\n",
    "    'High Effort Success', 'Low Effort Success', 'High Effort Failure', \n",
    "    'Low Effort Failure', 'Baseline'\n",
    "]\n",
    "\n",
    "human_means = [pd.Series([107, 57, 30, 35,86], index=_results_index),\n",
    "               pd.Series([96, 87, 38, 39,59], index=_results_index),\n",
    "               pd.Series([171, 94, 62, 45,81], index=_results_index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free parameters to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#COST = 0.5\n",
    "#B=6\n",
    "#A=60 \n",
    "#u_skill = .625 #mean of beta\n",
    "#tao_skill = 20 #variance of beta\n",
    "#skill=.4\n",
    "#scale = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_reward(e,diff,skill, A, B):\n",
    "    \"\"\"Return the probability of getting the reward\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    e : numeric or array-like\n",
    "        Description of this parameter.\n",
    "    # TODO: list other parameters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ...\n",
    "    \"\"\"\n",
    "    return 1/(1 + A * np.exp(-(e * skill / diff) * B)) ##plot for different As (moves function around) and Bs (changes sharpness)\n",
    "\n",
    "\n",
    "def get_effort_multidim(cost, diff, skill, A, B, reward=1):\n",
    "    \"\"\"Similar to `get_effort` but accepts arrays or single values of `diff` \n",
    "    and `skill`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Ndarray with same shape as `diff` and `skill`.\n",
    "    \"\"\"\n",
    "    es = np.linspace(0, 1, 100)\n",
    "    es_rank2 = es[np.newaxis, ...]\n",
    "    \n",
    "    try:\n",
    "        diff = diff[..., np.newaxis]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    try:\n",
    "        skill = skill[..., np.newaxis]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "    prob = prob_reward(e=es_rank2, diff=diff, skill=skill, A=A, B=B)\n",
    "    utilities = reward * prob - cost * es_rank2\n",
    "    return es[utilities.argmax(-1)]\n",
    "\n",
    "\n",
    "def your_eff_know_skill_opt(n_samples, cost, diff, skill, A, B,reward=1):\n",
    "    \"\"\"Model for planning.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "    cost : numeric\n",
    "    diff : array-like\n",
    "    skill : numeric\n",
    "    A : numeric\n",
    "    B : numeric\n",
    "    reward : numeric\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Ndarray of effort.\n",
    "    \"\"\"\n",
    "    rand_diffs = np.random.choice(diff, size=n_samples)\n",
    "    return get_effort_multidim(\n",
    "        cost=cost, diff=rand_diffs, skill=skill, A=A, B=B, reward=reward\n",
    "    )\n",
    "\n",
    "\n",
    "def create_priors_opt(n_samples, tao_skill, u_skill, cost, A, B, diff, reward=1, \n",
    "                      effort_threshold=0.5):\n",
    "    \"\"\"Documentation.\"\"\"\n",
    "    # Skill and diff are beta distributions.\n",
    "    skills = np.random.beta(\n",
    "        tao_skill * u_skill, (1 - u_skill) * tao_skill, size=n_samples,\n",
    "    )\n",
    "    \n",
    "    efforts = get_effort_multidim(\n",
    "        cost=cost, skill=skills, diff=diff, A=A, B=B,\n",
    "    )\n",
    "\n",
    "    high_effort = efforts > effort_threshold\n",
    "    success = prob_reward(efforts, diff, skills, A, B) > np.random.random(n_samples)\n",
    "\n",
    "    return skills,  success, high_effort\n",
    "\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that takes in free parameters and spits out model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_model_opt(cost, A, B, u_skill, tao_skill, n_samples=10000):\n",
    "    np.random.seed(0)\n",
    "    REWARD=1\n",
    "    high_diff = .8\n",
    "    low_diff = .2\n",
    "    \n",
    "    high_diff_skills, high_diff_success, high_diff_high_effort = create_priors_opt(\n",
    "        n_samples =n_samples, tao_skill=tao_skill, u_skill=u_skill, cost=cost, A=A, B=B, diff = high_diff\n",
    "    )\n",
    "\n",
    "    low_diff_skills, low_diff_success, low_diff_high_effort = create_priors_opt(\n",
    "        n_samples =n_samples, tao_skill=tao_skill, u_skill=u_skill, cost=cost, A=A, B=B, diff = low_diff\n",
    "    )\n",
    "    \n",
    "\n",
    "    skill_high_diff_high_eff = high_diff_skills[high_diff_success & high_diff_high_effort]\n",
    "    skill_high_diff_low_eff = high_diff_skills[high_diff_success & ~high_diff_high_effort]\n",
    "    skill_low_diff_high_eff = low_diff_skills[low_diff_success & low_diff_high_effort]\n",
    "    skill_low_diff_low_eff = low_diff_skills[low_diff_success & ~low_diff_high_effort]\n",
    "    \n",
    "    print  (np.mean(skill_high_diff_high_eff),np.mean(skill_high_diff_low_eff)) #low num, high num\n",
    "    print (np.mean(skill_low_diff_high_eff),np.mean(skill_low_diff_low_eff)) #low num, medium num\n",
    "    \n",
    "    return model_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.330751062018 0.711424141276\n",
      "0.0797093176182 0.627120673552\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'model_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b5129b27f771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-14a28acc443e>\u001b[0m in \u001b[0;36mrun_model_opt\u001b[0;34m(cost, A, B, u_skill, tao_skill, n_samples)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_low_diff_high_eff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_low_diff_low_eff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#low num, medium num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'model_means' is not defined"
     ]
    }
   ],
   "source": [
    "run_model_opt(.2, 1, 9, .5, 1,  n_samples=10000) #play with parameters\n",
    "\n",
    "#pass functions as parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optminize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrapped_run_model_opt_1(x):\n",
    "    model_means = run_model_opt(*x)\n",
    "    loss = rmse(model_means, human_means[0])\n",
    "    print (loss, x)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# key_words=dict(cost = 0.5,B=6,A=60 ,u_skill = .625 ,tao_skill = 20, skill=.4, scale =200)\n",
    "# rmse_val= run_model_opt(**key_words)\n",
    "\n",
    "inputs = np.array([0.5, 60, 6, .625, 20, .4, 200])\n",
    "minimum = optimize.fmin(wrapped_run_model_opt_1, inputs)\n",
    "minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_words=dict(cost =  0.40009476,B=6.71213053,A=55.69216106 ,u_skill =  0.70834897,\n",
    "               tao_skill = 18.78977603, skill=0.41762985, scale =201.32613568)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_means= run_model_opt(human_means[0], **key_words)[1]\n",
    "d = {\n",
    "    'Model' : pd.Series(model_means, index=_results_index),\n",
    "    'Human' : human_means[0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
