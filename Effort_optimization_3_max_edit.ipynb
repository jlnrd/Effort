{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e06ec623bce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-107>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3035\u001b[0m         \"\"\"\n\u001b[1;32m   3036\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3037\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \"\"\"\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import glob as glob\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import optimize\n",
    "\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = 10000\n",
    "threshold = .5 \n",
    "REWARD = 1\n",
    "\n",
    "_results_index = [\n",
    "    'High Effort Success', 'Low Effort Success', 'High Effort Failure', \n",
    "    'Low Effort Failure', 'Baseline'\n",
    "]\n",
    "\n",
    "human_means = [pd.Series([107, 57, 30, 35,86], index=_results_index),\n",
    "               pd.Series([96, 87, 38, 39,59], index=_results_index),\n",
    "               pd.Series([171, 94, 62, 45,81], index=_results_index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free parameters to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COST = 0.5\n",
    "#B=6\n",
    "#A=60 \n",
    "#u_skill = .625 #mean of beta\n",
    "#tao_skill = 20 #variance of beta\n",
    "#skill=.4\n",
    "#scale = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_reward(e,diff,skill, A, B):\n",
    "    \"\"\"Return the probability of getting the reward\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    e : numeric or array-like\n",
    "        Description of this parameter.\n",
    "    # TODO: list other parameters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ...\n",
    "    \"\"\"\n",
    "    return 1/(1 + A * np.exp(-(e * skill / diff) * B)) \n",
    "\n",
    "\n",
    "def get_effort_multidim(cost, diff, skill, A, B, reward=1):\n",
    "    \"\"\"Similar to `get_effort` but accepts arrays or single values of `diff` \n",
    "    and `skill`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Ndarray with same shape as `diff` and `skill`.\n",
    "    \"\"\"\n",
    "    es = np.linspace(0, 1, 100)\n",
    "    es_rank2 = es[np.newaxis, ...]\n",
    "    \n",
    "    try:\n",
    "        diff = diff[..., np.newaxis]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    try:\n",
    "        skill = skill[..., np.newaxis]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "    prob = prob_reward(e=es_rank2, diff=diff, skill=skill, A=A, B=B)\n",
    "    utilities = reward * prob - cost * es_rank2\n",
    "    return es[utilities.argmax(-1)]\n",
    "\n",
    "\n",
    "def your_eff_know_skill_opt(n_samples, cost, diff, skill, A, B,reward=1):\n",
    "    \"\"\"Model for planning.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "    cost : numeric\n",
    "    diff : array-like\n",
    "    skill : numeric\n",
    "    A : numeric\n",
    "    B : numeric\n",
    "    reward : numeric\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Ndarray of effort.\n",
    "    \"\"\"\n",
    "    rand_diffs = np.random.choice(diff, size=n_samples)\n",
    "    return get_effort_multidim(\n",
    "        cost=cost, diff=rand_diffs, skill=skill, A=A, B=B, reward=reward\n",
    "    )\n",
    "\n",
    "\n",
    "def create_priors_opt(n_samples, tao_skill, u_skill, cost, A, B, diff, reward=1, \n",
    "                      effort_threshold=0.5):\n",
    "    \"\"\"Documentation.\"\"\"\n",
    "    # Skill and diff are beta distributions.\n",
    "    skills = np.random.beta(\n",
    "        tao_skill * u_skill, (1 - u_skill) * tao_skill, size=n_samples,\n",
    "    )\n",
    "    \n",
    "    efforts = get_effort_multidim(\n",
    "        cost=cost, skill=skills, diff=diffs, A=A, B=B,\n",
    "    )\n",
    "\n",
    "    high_effort = efforts > effort_threshold\n",
    "    success = prob_reward(efforts, diffs, skills, A, B) > np.random.random(n_samples)\n",
    "\n",
    "    return skills,  success, high_effort\n",
    "\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that takes in free parameters and spits out model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_opt(cost, A, B, u_skill, tao_skill, skill, scale, u_diff = 0.5, tao_diff = 1, n_samples=10000):\n",
    "    np.random.seed(0)\n",
    "    REWARD=1\n",
    "    high_diff = .8\n",
    "    low_diff = .2\n",
    "    \n",
    "    high_diff_skills, high_diff_success, high_diff_high_effort = create_priors_opt(\n",
    "        n_samples =n_samples, tao_skill=tao_skill, u_skill=u_skill, cost=cost, A=A, B=B, diff = high_diff\n",
    "    )\n",
    "\n",
    "    low_diff_skills, low_diff_success, low_diff_high_effort = create_priors_opt(\n",
    "        n_samples =n_samples, tao_skill=tao_skill, u_skill=u_skill, cost=cost, A=A, B=B, diff = low_diff\n",
    "    )\n",
    "    \n",
    "\n",
    "    skill_high_diff_high_eff = high_skills[high_success & high_diff_high_effort]\n",
    "    skill_high_diff_low_eff = skills[success & high_diff & low_effort]\n",
    "    skill_low_diff_high_eff = skills[success & low_diff & high_effort]\n",
    "    skill_low_diff_low_eff = skills[success & low_diff & low_effort]\n",
    "    \n",
    "    \n",
    "    effort_high_success = your_eff_know_skill_opt(n_samples, cost, diffs[success & high_effort],skill, A,B) \n",
    "    effort_low_success = your_eff_know_skill_opt(n_samples,  cost, diffs[success & (~high_effort)],skill,A,B) \n",
    "    effort_high_fail = your_eff_know_skill_opt(n_samples,  cost, diffs[(~success) & high_effort],skill,A,B) \n",
    "    effort_low_fail = your_eff_know_skill_opt(n_samples,  cost, diffs[(~success) & (~high_effort)],skill,A,B) \n",
    "    effort_baseline = your_eff_know_skill_opt(n_samples,  cost, np.random.beta(tao_diff*u_diff, (1-u_diff)*tao_diff, size=n_samples),skill,A,B)\n",
    "\n",
    "    model_means = np.stack(\n",
    "        (effort_high_success, effort_low_success, effort_high_fail, \n",
    "         effort_low_fail, effort_baseline),\n",
    "    ).mean(-1)\n",
    "    model_means *= scale\n",
    "    \n",
    "    return model_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optminize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_run_model_opt_1(x):\n",
    "    model_means = run_model_opt(*x)\n",
    "    loss = rmse(model_means, human_means[0])\n",
    "    print (loss, x)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# key_words=dict(cost = 0.5,B=6,A=60 ,u_skill = .625 ,tao_skill = 20, skill=.4, scale =200)\n",
    "# rmse_val= run_model_opt(**key_words)\n",
    "\n",
    "inputs = np.array([0.5, 60, 6, .625, 20, .4, 200])\n",
    "minimum = optimize.fmin(wrapped_run_model_opt_1, inputs)\n",
    "minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words=dict(cost =  0.40009476,B=6.71213053,A=55.69216106 ,u_skill =  0.70834897,\n",
    "               tao_skill = 18.78977603, skill=0.41762985, scale =201.32613568)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_means= run_model_opt(human_means[0], **key_words)[1]\n",
    "d = {\n",
    "    'Model' : pd.Series(model_means, index=_results_index),\n",
    "    'Human' : human_means[0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "* difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_run_model_opt_2(x):\n",
    "    rmse = run_model_opt(\n",
    "                         cost=key_words['cost'], \n",
    "                         A=key_words['A'], \n",
    "                         B=key_words['B'], \n",
    "                         u_skill=key_words['u_skill'], \n",
    "                         tao_skill=key_words['tao_skill'], \n",
    "                         skill=key_words['skill'], \n",
    "                         scale=key_words['scale'],\n",
    "                         u_diff = x[0],\n",
    "#                          tao_diff = x[1]\n",
    "                        )\n",
    "#     print(rmse, x)\n",
    "    loss = rmse(model_means, human_means[1])\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# key_words=dict(cost = 0.5,B=6,A=60 ,u_skill = .625 ,tao_skill = 20, skill=.4, scale =200)\n",
    "# rmse_val= run_model_opt(**key_words)\n",
    "\n",
    "minimum = optimize.fmin(wrapped_run_model_opt_2, [0.7])\n",
    "minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_means= run_model_opt(human_means[1], \n",
    "                           u_diff=.5, \n",
    "                           tao_diff=1, \n",
    "                           **key_words)[1]\n",
    "d = {\n",
    "    'Model' : pd.Series(model_means, index=_results_index),\n",
    "    'Human' : human_means[1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "* moral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_run_model_opt_3(x):\n",
    "    rmse = run_model_opt(\n",
    "                         cost=x, \n",
    "                         A=key_words['A'], \n",
    "                         B=key_words['B'], \n",
    "                         u_skill=key_words['u_skill'], \n",
    "                         tao_skill=key_words['tao_skill'], \n",
    "                         skill=key_words['skill'], \n",
    "                         scale=key_words['scale']\n",
    "                        )\n",
    "    loss = rmse(model_means, human_means[2])\n",
    "\n",
    "    print(loss, x)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# key_words=dict(cost = 0.5,B=6,A=60 ,u_skill = .625 ,tao_skill = 20, skill=.4, scale =200)\n",
    "# rmse_val= run_model_opt(**key_words)\n",
    "\n",
    "minimum = optimize.fmin(wrapped_run_model_opt_3, .4)\n",
    "minimum\n",
    "words = dict(key_words)\n",
    "words['cost'] = minimum[0]\n",
    "model_means= run_model_opt(human_means[2], \n",
    "                           **words)[1]\n",
    "d = {\n",
    "    'Model' : pd.Series(model_means, index=_results_index),\n",
    "    'Human' : human_means[2]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Joint Optimization across 3 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def wrapped_run_model_opt_joint(x):\n",
    "    exp1 = run_model_opt(\n",
    "        cost = x[0], \n",
    "        A = x[1], \n",
    "        B = x[2], \n",
    "        u_skill = x[3], \n",
    "        tao_skill = x[4], \n",
    "        skill = x[5], \n",
    "        scale = x[6], \n",
    "        u_diff = 0.5, \n",
    "    )\n",
    "    \n",
    "    exp2 = run_model_opt(\n",
    "        cost = x[0], \n",
    "        A = x[1], \n",
    "        B = x[2], \n",
    "        u_skill = x[3], \n",
    "        tao_skill = x[4], \n",
    "        skill = x[5], \n",
    "        scale = x[6], \n",
    "        u_diff = x[7], \n",
    "    )\n",
    "    \n",
    "    exp3 = run_model_opt(\n",
    "        cost = x[8], \n",
    "        A = x[1], \n",
    "        B = x[2], \n",
    "        u_skill = x[3], \n",
    "        tao_skill = x[4], \n",
    "        skill = x[5], \n",
    "        scale = x[6], \n",
    "        u_diff = 0.5, \n",
    "    )        \n",
    "    model = np.array(list(exp1)+list(exp2)+list(exp3))\n",
    "    human = np.array(list(human_means[0])+list(human_means[1])+list(human_means[2]))\n",
    "    loss = rmse(model, human)\n",
    "    print(loss, x)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# key_words=dict(cost = 0.5,B=6,A=60 ,u_skill = .625 ,tao_skill = 20, skill=.4, scale =200)\n",
    "# rmse_val= run_model_opt(**key_words)\n",
    "\n",
    "minimum = optimize.fmin(wrapped_run_model_opt_joint, [   0.40009476,   55.69216106,    6.71213053,    0.70834897,\n",
    "         18.78977603,    0.41762985,  201.32613568, .6, .3])\n",
    "minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x = minimum\n",
    "    exp1 = run_model_opt(\n",
    "        cost = x[0], \n",
    "        A = x[1], \n",
    "        B = x[2], \n",
    "        u_skill = x[3], \n",
    "        tao_skill = x[4], \n",
    "        skill = x[5], \n",
    "        scale = x[6], \n",
    "        u_diff = 0.5, \n",
    "    )\n",
    "    \n",
    "    exp2 = run_model_opt(\n",
    "        cost = x[0], \n",
    "        A = x[1], \n",
    "        B = x[2], \n",
    "        u_skill = x[3], \n",
    "        tao_skill = x[4], \n",
    "        skill = x[5], \n",
    "        scale = x[6], \n",
    "        u_diff = x[7], \n",
    "    )\n",
    "    \n",
    "    exp3 = run_model_opt(\n",
    "        cost = x[8], \n",
    "        A = x[1], \n",
    "        B = x[2], \n",
    "        u_skill = x[3], \n",
    "        tao_skill = x[4], \n",
    "        skill = x[5], \n",
    "        scale = x[6], \n",
    "        u_diff = 0.5, \n",
    "    )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=list(human_means[0])+list(human_means[1])+list(human_means[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=list(exp1)+list(exp2)+list(exp3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(h,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not fitting correctly\n",
    "* baseline hard\n",
    "* moral low effort success and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m,h,'.')\n",
    "np.corrcoef(m,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
