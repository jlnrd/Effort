{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_samples = 10000\n",
    "threshold = .5 \n",
    "REWARD = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free parameters to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COST = 0.5\n",
    "B=6\n",
    "A=60 \n",
    "u_skill = .625 #mean of beta\n",
    "tao_skill = 20 #variance of beta\n",
    "skill=.4\n",
    "scale = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prob_reward(e,diff,skill, A, B):\n",
    "    return 1/(1 + A * np.exp(-(e * skill / diff) * B)) \n",
    "\n",
    "def get_effort(reward, cost, diff, skill, A, B):\n",
    "    Us=list()\n",
    "    es = np.linspace(0, 1, 100) \n",
    "    for i in es:\n",
    "        U=reward*prob_reward(i, diff, skill, A, B)-cost*i #utility function\n",
    "        Us.append(U)\n",
    "    return es[np.argmax(Us)], Us, es  #return argmax of utility, and utilities \n",
    "\n",
    "def your_eff_know_skill(reward, cost, diff,skill, A, B):  #model for planning. Takes in diff, skill, and cost -returns effort\n",
    "    sampled_effort= list()\n",
    "    sampled_skill=list()\n",
    "    for i in xrange(N_samples):\n",
    "        d = np.random.choice(diff)\n",
    "        effort,_,_=get_effort(reward, cost, d, skill, A, B)\n",
    "        sampled_effort.append(effort)\n",
    "        sampled_skill.append(skill)\n",
    "    \n",
    "    return sampled_effort\n",
    "\n",
    "def create_priors(N_samples, tao_skill,u_skill, A, B, COST):\n",
    "    output = {\n",
    "        'sampled_skill_high':[],'sampled_diff_high':[],'sampled_skill_low':[],'sampled_diff_low':[],\n",
    "        'sampled_skill_low_fail':[],' sampled_diff_low_fail':[],'sampled_diff_low_fail':[],'sampled_skill_high_fail':[],\n",
    "        'sampled_diff_high_fail':[],'diff_samp':[],'skill_samp':[],'effort_samp':[],'success_samp':[]}\n",
    "    for _ in xrange(N_samples):\n",
    "        skill = np.random.beta(tao_skill*u_skill,(1-u_skill)*tao_skill) #skill is a beta function\n",
    "        diff = np.random.beta(.5,.5) #difficulty is a beta function\n",
    "        effort,_,_ = get_effort(REWARD, COST, diff, skill, A, B) \n",
    "        high_effort = effort > threshold\n",
    "        success = prob_reward(effort,diff,skill, A, B) > np.random.random()\n",
    "\n",
    "        output['diff_samp'].append(diff)\n",
    "        output['skill_samp'].append(skill)\n",
    "        output['effort_samp'].append(effort)\n",
    "        output['success_samp'].append(success)\n",
    "        if success and high_effort: \n",
    "            output['sampled_skill_high'].append(skill)\n",
    "            output['sampled_diff_high'].append(diff)\n",
    "        elif success and not high_effort: \n",
    "            output['sampled_skill_low'].append(skill)\n",
    "            output['sampled_diff_low'].append(diff)\n",
    "        elif not success and not high_effort: \n",
    "            output['sampled_skill_low_fail'].append(skill)\n",
    "            output['sampled_diff_low_fail'].append(diff)\n",
    "        elif not success and high_effort: \n",
    "            output['sampled_skill_high_fail'].append(skill)\n",
    "            output['sampled_diff_high_fail'].append(diff)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function that takes in free parameters and spits out model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REWARD=1\n",
    "def run_model(cost, A, B, u_skill,tao_skill, skill):\n",
    "    efforthigh_success=list()\n",
    "    effortlow_success=list()\n",
    "    efforthigh_fail = list()\n",
    "    effortlow_fail=list()\n",
    "    effortbaseline =list()\n",
    "    priors= create_priors(1000, tao_skill,u_skill, A,B,cost)\n",
    "    effort_high_success = your_eff_know_skill(REWARD, cost, priors['sampled_diff_high'],skill, A,B) \n",
    "    efforthigh_success.append(effort_high_success)\n",
    "    effort_low_success = your_eff_know_skill(REWARD, cost, priors['sampled_diff_low'],skill,A,B) \n",
    "    effortlow_success.append(effort_low_success)\n",
    "    effort_high_fail = your_eff_know_skill(REWARD, cost, priors['sampled_diff_high_fail'],skill,A,B) \n",
    "    efforthigh_fail.append(effort_high_fail)\n",
    "    effort_low_fail = your_eff_know_skill(REWARD, cost, priors['sampled_diff_low_fail'],skill,A,B) \n",
    "    effortlow_fail.append(effort_low_fail)\n",
    "    effort_baseline = your_eff_know_skill(REWARD, cost, np.random.beta(.5, .5, size=1000),skill,A,B)\n",
    "    effortbaseline.append(effort_baseline)\n",
    "    \n",
    "    return efforthigh_success, effortlow_success, efforthigh_fail, effortlow_fail, effortbaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words=dict(cost = 0.5,B=6,A=60 ,u_skill = .625 ,tao_skill = 20, skill=.4)\n",
    "\n",
    "efforthigh_success, effortlow_success, efforthigh_fail, effortlow_fail, effortbaseline = run_model(**key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.463636363636\n"
     ]
    }
   ],
   "source": [
    "print np.mean(efforthigh_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run functions to get effort predictions per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.418507070707\n",
      "0.26246969697\n",
      "0.0\n",
      "0.0446545454545\n",
      "0.283003030303\n"
     ]
    }
   ],
   "source": [
    "sampled_diff_high, sampled_diff_low, sampled_diff_low_fail,sampled_diff_high_fail= create_priors(100, tao_skill,u_skill)\n",
    "effort_high_success = your_eff_know_skill(REWARD, COST, sampled_diff_high,skill,A,B) \n",
    "effort_low_success = your_eff_know_skill(REWARD, COST, sampled_diff_low,skill,A,B) \n",
    "effort_high_fail = your_eff_know_skill(REWARD, COST, sampled_diff_high_fail,skill,A,B) \n",
    "effort_low_fail = your_eff_know_skill(REWARD, COST, sampled_diff_low_fail,skill,A,B) \n",
    "#effort_baseline = your_eff_know_skill(REWARD, COST, np.random.beta(tao_skill*u_skill,(1-u_skill)*tao_skill, size=1000),skill) ##change? \n",
    "effort_baseline = your_eff_know_skill(REWARD, COST, np.random.beta(.5, .5, size=100),skill,A,B) ##change? \n",
    "\n",
    "\n",
    "print np.mean(effort_high_success)\n",
    "print np.mean(effort_low_success)\n",
    "print np.mean(effort_high_fail)\n",
    "print np.mean(effort_low_fail)\n",
    "print np.mean(effort_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{numpy.float64}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([type(i) for i in effort_baseline])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
